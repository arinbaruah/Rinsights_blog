{
  "hash": "eea0d75b4984e75521802c30240648df",
  "result": {
    "markdown": "---\ntitle: \"Performing a high-dimensional data analysis and what does it mean for us ?\"\nauthor: \"Arindom Baruah\"\ndate: \"2024-03-25\"\nquarto-required: \">=1.3.0\"\nformat:\n    html:\n        output-file: post.html\nexecute: \n  echo: false\n  message: false\n  warning: false\nnumber-sections: true\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n# ML concepts\n\n## a) Model accuracy\n\n\n\n::: {#tbl-data .cell tbl-cap='Sample rows of the current data'}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> y </th>\n   <th style=\"text-align:left;\"> pred1 </th>\n   <th style=\"text-align:left;\"> pred2 </th>\n   <th style=\"text-align:right;\"> bilby1 </th>\n   <th style=\"text-align:right;\"> bilby2 </th>\n   <th style=\"text-align:right;\"> quokka1 </th>\n   <th style=\"text-align:right;\"> quokka2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:right;\"> 0.8 </td>\n   <td style=\"text-align:right;\"> 0.80 </td>\n   <td style=\"text-align:right;\"> 0.2 </td>\n   <td style=\"text-align:right;\"> 0.20 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:right;\"> 0.9 </td>\n   <td style=\"text-align:right;\"> 0.51 </td>\n   <td style=\"text-align:right;\"> 0.1 </td>\n   <td style=\"text-align:right;\"> 0.49 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:left;\"> bilby </td>\n   <td style=\"text-align:right;\"> 0.9 </td>\n   <td style=\"text-align:right;\"> 0.60 </td>\n   <td style=\"text-align:right;\"> 0.1 </td>\n   <td style=\"text-align:right;\"> 0.40 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\nThe computations to assess the model metrics are delineated in the panel tabsets below.\n\n:::panel-tabset\n\n### Model 1 \n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\nThe accuracy for `model 1` which is calculated based on the number of true positives and the true negatives is observed to be __0.778__.\n\nHowever, the accuracy parameter for a model may not always be the best indicator. This is especially true when the data may contain unbalanced class distribution. In this case, we will rely on balanced accuracy which is based on the true positive and the true negative rate of prediction for the model.\n\nThe balanced accuracy for `model 1` is found to be __0.775__.\n\n@fig-confmat1 illustrates the detailed confusion matrix for `model 1` with the critical model parameters which are useful indicators of model performance.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Confusion matrix with key performance metrics of model 1](conf_mat_files/figure-html/fig-confmat1-1.png){#fig-confmat1 width=672}\n:::\n:::\n\n\n### Model 2 \n\n\n\n\n::: {.cell}\n\n:::\n\n\nThe accuracy for `model 2` which is calculated based on the number of true positives and the true negatives is observed to be __0.63__. The balanced accuracy for the same model which is based on the true positive and the true negative rates are  __0.629__.\n\n@fig-confmat2 illustrates the detailed confusion matrix for `model 2`. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![Confusion matrix with key performance metrics of model 2](conf_mat_files/figure-html/fig-confmat2-1.png){#fig-confmat2 width=672}\n:::\n:::\n\n\n\n\n:::\n\n:::{.callout-note}\n# Key takeaway\n\nAs we can observe from the model metrics in @fig-confmat1 and @fig-confmat2, the model 1 was observed to classify the labelled data more accurately than model 2.\n:::\n## b) Sensitivity and Specificity with revised threshold values\n\n\n:::panel-tabset\n\n### Classification threshold of 0.3\n\n__1) When the threshold value for classification in model 1 is 0.3__\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Confusion matrix with key performance metrics of model 1 when considering 0.3 as the threshold value for positive Bilby classification](conf_mat_files/figure-html/fig-confmat_new_1a-1.png){#fig-confmat_new_1a width=672}\n:::\n:::\n\n\nThe sensitivity for `model 1` when the threshold value for positive Bilby classification is 0.3 and above is __0.958__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __0.767__.\n\n__2) When the threshold value for classification in model 2 is 0.3__\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Confusion matrix with key performance metrics of model 2 when considering 0.3 as the threshold value for positive Bilby classification](conf_mat_files/figure-html/fig-confmat_new_2a-1.png){#fig-confmat_new_2a width=672}\n:::\n:::\n\nThe sensitivity for `model 2` when the threshold value for positive Bilby classification is 0.3 and above is __0.833__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __0.667__. Other detailed model performance metrics for model 2 with a threshold value of 0.3 can be referred to in @fig-confmat_new_2a.\n\n### Classification threshold of 0.4\n\n__1) When the threshold value for classification in model 1 is 0.4__\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Confusion matrix with key performance metrics of model 1 when considering 0.4 as the threshold value for positive Bilby classification](conf_mat_files/figure-html/fig-confmat_new_1b-1.png){#fig-confmat_new_1b width=672}\n:::\n:::\n\n\nThe sensitivity for `model 1` when the threshold value for positive Bilby classification is 0.4 and above is __0.917__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __0.5__. Other detailed model performance metrics for model 1 with a threshold value of 0.4 can be referred to in @fig-confmat_new_1b.\n\n\n__2) When the threshold value for classification in model 2 is 0.4__\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Confusion matrix with key performance metrics of model 2 when considering 0.4 as the threshold value for positive Bilby classification](conf_mat_files/figure-html/fig-confmat_new_2b-1.png){#fig-confmat_new_2b width=672}\n:::\n:::\n\n\nThe sensitivity for `model 2` when the threshold value for positive Bilby classification is 0.4 and above is __0.833__. The value for __1-Specificity__ for the same model which is based on the true positive and the true negative rates is  __0.467__. Other detailed model performance metrics for model 2 with a threshold value of 0.4 can be referred to in @fig-confmat_new_2b.\n\n\n:::\n\n## c) Receiver Operative Curve (ROC) visualisation for model output\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Receiver Operative Curve visualisation for comparison of model performance based on Sensitivty and 1-Specificity](conf_mat_files/figure-html/fig-roc-1.png){#fig-roc width=672}\n:::\n:::\n\n\n:::{.callout-note}\n# Key takeaway\n\nThe __higher the curve is to the top left point of the plot, the higher the true positive rate of the model (measured through sensitivity) as well as the least false positive rate (measured through 1-specificity)__. This is often termed as the most ideal model as shown in @fig-roc by the <span style=color:darkgreen>darkgreen line</span>.\n\nAs we can also observe in the plot, the area covered by the ROC of __model 1 is larger when in comparison to model 2__. This indicates that the __model 1 is performing better than the results obtained through model 2__.\n\nWe can additionally obtain a metric of the ROC by computing the area covered under each of these plotted curves. This is termed as the Area Under Curve (AUC) and are as follows:\n\nAUC for model 1 is __0.835.__ \\\nAUC for model 2 is __0.645.__\n\nBased on the AUC values, we can clearly observe __that model 1 performs better than model 2.__\n:::\n\n## References\n\n1. __tourr__: Hadley Wickham, Dianne Cook, Heike Hofmann, Andreas Buja\n  (2011). tourr: An R Package for Exploring Multivariate\n  Data with Projections. Journal of Statistical Software,\n  40(2), 1-18. URL http://www.jstatsoft.org/v40/i02/.\n  \n2. __tidymodels__:  Kuhn et al., (2020). Tidymodels: a collection of packages for modeling and machine learning using\n  tidyverse principles. https://www.tidymodels.org.  \n  \n3. __tidyverse__: Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M,\n  Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C,\n  Woo K, Yutani H (2019). “Welcome to the tidyverse.” _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.\n  \n4. __kableExtra__: Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe Syntax_. R package version 1.4.0,\n  <https://CRAN.R-project.org/package=kableExtra>.\n  \n5. __caret__: Kuhn, M. (2008). Building Predictive Models in R Using the caret Package. Journal of Statistical Software, 28(5),\n  1–26. https://doi.org/10.18637/jss.v028.i05.\n\n6. __plotROC__: Michael C. Sachs (2017). plotROC: A Tool for Plotting ROC Curves. Journal of Statistical Software, Code Snippets,\n  79(2), 1-19. doi:10.18637/jss.v079.c02.\n\n7. __mulgar__: Cook D, Laa U (2023). _mulgar: Functions for Pre-Processing Data for Multivariate Data Visualisation using Tours_. R\n  package version 1.0.2, <https://CRAN.R-project.org/package=mulgar>.\n  \n8. __uwot__: Melville J (2023). _uwot: The Uniform Manifold Approximation and Projection (UMAP) Method for Dimensionality\n  Reduction_. R package version 0.1.16, <https://CRAN.R-project.org/package=uwot>.\n  \n9. __GGally__: Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A, Crowley J (2024). _GGally: Extension to\n  'ggplot2'_. R package version 2.2.1, <https://CRAN.R-project.org/package=GGally>.\n\n10. __animation__: Yihui Xie (2013). animation: An R Package for Creating Animations and Demonstrating Statistical Methods. Journal of\n  Statistical Software, 53(1), 1-27. URL https://doi.org/10.18637/jss.v053.i01.\n  \n11. __magick__: Ooms J (2024). _magick: Advanced Graphics and Image-Processing in R_. R package version 2.8.3,\n  <https://CRAN.R-project.org/package=magick>.\n\n12. __plotly__: C. Sievert. Interactive Web-Based Data Visualization with R, plotly, and shiny. Chapman and Hall/CRC Florida, 2020.\n\n13. __ggfortify__: Yuan Tang, Masaaki Horikoshi, and Wenxuan Li. \"ggfortify: Unified Interface to Visualize Statistical Result of Popular R Packages.\" The R Journal 8.2 (2016): 478-489.\n\n14. OpenAI (2023). ChatGPT (version 3.5) [Large language model]. https://chat.openai.com/chat, full script of conversation [here](https://chat.openai.com/share/34c580ef-3332-4db5-8de3-7ff6b80a4a09)\n\n\n\n\n\n\n",
    "supporting": [
      "conf_mat_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}